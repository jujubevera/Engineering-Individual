{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Team: Data Magicians\n",
    "Members:\n",
    "<p>\n",
    "Arda Putra Ryandika\n",
    "</p>\n",
    "<p>\n",
    "Atthaya Busayaruengrat (Hong)\n",
    "</p>\n",
    "<p>\n",
    "Jingxue (Vera) Cao\n",
    "</p>\n",
    "<p>\n",
    "Katharina Wiedmann  \n",
    "</p>\n",
    "<p>\n",
    "Ying Tung (Debbie) Lau\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "In this project, we are taking three sources of movie review data (csv, tsv, web scraping) and aiming to create weak labelling functions based on the data. The objective of the project is to compare the performance of a machine learning based classifier with 3000 datapoints compared to 3000 + another 12000 weak labeled datapoints. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Review Data\n",
    "\n",
    "We split the work of obtaining data to three group members (Hong, Debbie, Vera) . Hong was responsible for scraping movie reviews from the rotten tomato website, while Debbie and Vera sought for other data formats like tsv and csv to ensure the sufficiency of data sample. \n",
    "\n",
    "The dataset contains two columns: one is the text review posted by people, another is the label 1 or 0. 1 indicates a positive review (fresh), and 0 indicates an non-positive review (not fresh).\n",
    "\n",
    "The final dataset consists of 15000 reviews in total, with 5000 from web scrapping, 5000 from csv file, and 5000 from tsv file. \n",
    "\n",
    "We further sampled 2000 data points for labelling function development (development data set) and made sure the positive and non-positive reviews had the same amounts. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Labelling functions\n",
    "\n",
    "Meanwhile, the rest of the team members worked on generating weak labelling functions based on the findings in data exploration. \n",
    "\n",
    "During data exploration, as implementing spark slowed down the computation process as it partitions the dataset, we chose to use pandas to notice any patterns and differences in positive and non-positive reviews. We faced a few challenges in this stage. For example, we built a lemmatization function on the word count dataframe to avoid classifier bias caused by word inflections. However, many words were converted into completely different words incorrectly. Due to the mis-correction on words, we decided not to use lemmatization. \n",
    "\n",
    "As for building the labelling functions, Katie looked for stop words in the review first and counted the word occurrences in positive reviews and negative reviews. By identifying the difference in the word occurrences, we built our labelling functions to separate positive and non-positive reviews based on exclusive words. \n",
    "\n",
    "We also looked for capital letters mentioned in each type of reviews, but since the capital letters were irrelevant to emotions and most didn’t make sense for understanding, we decided not to create a labelling function based on it.\n",
    "\n",
    "As we noticed keywords like “too” and “far” occurred more often in a specific type of reviews, so other labelling functions were created based on the keywords. \n",
    "Similarly, exclamation mark and question mark also appeared more often in one type of reviews, so we created labelling functions based on them as well.\n",
    "\n",
    "After finalising the labeling functions, Arda built a classifier to combine the labeling functions together. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building classifiers \n",
    "\n",
    "Arda was responsible for building a NLP classifier, which will be later applied to compare with the labelling function classifier. This model was done by utilizing tokens generated from two types of reviews and fed as features. This NLP classifier yielded 70% accuracy on the testing set. \n",
    "Arda also implemented the spark on Faculty so that the following labelling functions can be implemented in a spark environment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "After analysing the performance of our labelling functions, we selected those with higher accuracy and fewer conflicts to generate our model. We applied two methods, Majority Label Voter and Label Model, to see the difference in accuracy. According to the result, the Majority Vote got a slightly higher accuracy of 60.9%,  compared to a 60.2% accuracy of Label Model.\n",
    "Finally, we built a classifier based on extra 10000 weak labelled data points, and the classifier yielded an accuracy of 58.2%. In terms of the classifier created from 3000 data points, it obtained a higher accuracy of 62%.\n",
    "\n",
    "We thought the difference in accuracy was mainly due to the inefficiency to separate two classes  of the labelling functions. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GitHub\n",
    "Every time we made a change, we used terminal in Faculty to push the changes to our group repository. \n",
    "After committing the change, we used “git status” to double check the state of repository. Using “git diff” also enables us to see all the changes in repository.\n",
    "\n",
    "Link to GitHub repository:\n",
    "https://github.com/KatharinaWiedmann/DataEngGroupProject.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JIRA board \n",
    "We used JIRA to manage the progress of our project and record our meeting topics. The brief of meetings is shown as below:\n",
    "<p>\n",
    "First meeting:\n",
    "•\tRotten Tomatoes labelling functions - good movie or not (positive/ negative rating). \n",
    "•\tTwitter data: Labelling whether someone is a Boris Johnson supporter or not. \n",
    "•\tYouTube comments: positive or negative comment \n",
    "•\tPromotion emails - is an email a spam email or a genuine email. \n",
    "</p>\n",
    "<p>\n",
    "Second meeting:\n",
    "•\tLabelling functions (Vera, Debbie, Katie) \n",
    "•\tClassifier (Arda) \n",
    "•\tWeb Scraping (Hong) \n",
    "•\tGitHub (Katie)\n",
    "</p>\n",
    "<p>\n",
    "Third meeting:\n",
    "•\tRewriting labelling functions (SparkLFApplier - done together)\n",
    "•\tCombining labelling functions (Hong & Katie)\n",
    "•\tAnalyzing summary/ results labelling functions (Hong & Katie)\n",
    "•\tPlug in classifier (Arda)\n",
    "•\tCompare results between using labelling functions and not labelling functions (Arda)\n",
    "•\tIterate on Mark-up/ write-down (Vera)\n",
    "•\tJIRA cleanup & additional notes (Katie)\n",
    "•\tGithub reminder - don't forget to push/ pull (everyone)\n",
    "•\tMake sensitivity analysis work (Debbie) \n",
    "•\tnt function (Hong)\n",
    "</p>\n",
    "\n",
    "Further details can be found at:\n",
    "http://csjira2.cs.ucl.ac.uk:8080/secure/RapidBoard.jspa?rapidView=316&view=detail&selectedIssue=DED-16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - pandas==0.24.2\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    pandas-0.24.2              |   py36he6710b0_0         8.5 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         8.5 MB\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  pandas                               1.0.1-py36h0573a6f_0 --> 0.24.2-py36he6710b0_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "pandas-0.24.2        | 8.5 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install pandas==0.24.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    bokeh-2.0.0                |           py36_0         5.2 MB\n",
      "    dask-2.12.0                |             py_0          13 KB\n",
      "    dask-core-2.12.0           |             py_0         568 KB\n",
      "    decorator-4.4.2            |             py_0          14 KB\n",
      "    distributed-2.12.0         |           py36_0         952 KB\n",
      "    gunicorn-20.0.4            |           py36_0         125 KB\n",
      "    ipython-7.13.0             |   py36h5ca1d4c_0         978 KB\n",
      "    libssh2-1.9.0              |       h1ba5d50_1         269 KB\n",
      "    nb_conda_kernels-2.2.2     |           py36_0          39 KB\n",
      "    packaging-20.3             |             py_0          36 KB\n",
      "    plotly-4.5.2               |             py_0         1.6 MB\n",
      "    psutil-5.7.0               |   py36h7b6447c_0         315 KB\n",
      "    qtconsole-4.7.1            |             py_0          94 KB\n",
      "    requests-2.23.0            |           py36_0          91 KB\n",
      "    setuptools-46.0.0          |           py36_0         519 KB\n",
      "    tornado-6.0.4              |   py36h7b6447c_1         597 KB\n",
      "    typing_extensions-3.7.4.1  |           py36_0          40 KB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:        11.4 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  typing_extensions  pkgs/main/linux-64::typing_extensions-3.7.4.1-py36_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  bokeh                                        1.4.0-py36_0 --> 2.0.0-py36_0\n",
      "  dask                                          2.11.0-py_0 --> 2.12.0-py_0\n",
      "  dask-core                                     2.11.0-py_0 --> 2.12.0-py_0\n",
      "  decorator                                      4.4.1-py_0 --> 4.4.2-py_0\n",
      "  distributed                                 2.11.0-py36_0 --> 2.12.0-py36_0\n",
      "  gunicorn                                    19.9.0-py36_0 --> 20.0.4-py36_0\n",
      "  ipython                             7.12.0-py36h5ca1d4c_0 --> 7.13.0-py36h5ca1d4c_0\n",
      "  libssh2                                  1.8.2-h1ba5d50_0 --> 1.9.0-h1ba5d50_1\n",
      "  nb_conda_kernels                             2.1.1-py36_1 --> 2.2.2-py36_0\n",
      "  packaging                                       20.1-py_0 --> 20.3-py_0\n",
      "  pandas                              0.24.2-py36he6710b0_0 --> 1.0.1-py36h0573a6f_0\n",
      "  plotly                                         4.5.0-py_0 --> 4.5.2-py_0\n",
      "  psutil                               5.6.7-py36h7b6447c_0 --> 5.7.0-py36h7b6447c_0\n",
      "  qtconsole                                      4.6.0-py_1 --> 4.7.1-py_0\n",
      "  requests                                    2.22.0-py36_1 --> 2.23.0-py36_0\n",
      "  setuptools                                  45.2.0-py36_0 --> 46.0.0-py36_0\n",
      "  tornado                              6.0.3-py36h7b6447c_3 --> 6.0.4-py36h7b6447c_1\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "gunicorn-20.0.4      | 125 KB    | ##################################### | 100% \n",
      "qtconsole-4.7.1      | 94 KB     | ##################################### | 100% \n",
      "typing_extensions-3. | 40 KB     | ##################################### | 100% \n",
      "ipython-7.13.0       | 978 KB    | ##################################### | 100% \n",
      "plotly-4.5.2         | 1.6 MB    | ##################################### | 100% \n",
      "packaging-20.3       | 36 KB     | ##################################### | 100% \n",
      "tornado-6.0.4        | 597 KB    | ##################################### | 100% \n",
      "decorator-4.4.2      | 14 KB     | ##################################### | 100% \n",
      "distributed-2.12.0   | 952 KB    | ##################################### | 100% \n",
      "dask-2.12.0          | 13 KB     | ##################################### | 100% \n",
      "psutil-5.7.0         | 315 KB    | ##################################### | 100% \n",
      "nb_conda_kernels-2.2 | 39 KB     | ##################################### | 100% \n",
      "bokeh-2.0.0          | 5.2 MB    | ##################################### | 100% \n",
      "requests-2.23.0      | 91 KB     | ##################################### | 100% \n",
      "dask-core-2.12.0     | 568 KB    | ##################################### | 100% \n",
      "libssh2-1.9.0        | 269 KB    | ##################################### | 100% \n",
      "setuptools-46.0.0    | 519 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: / b'+ /opt/anaconda/envs/Python3/bin/python -m nb_conda_kernels.install --disable --prefix=/opt/anaconda/envs/Python3\\nDisabling nb_conda_kernels...\\nDisabled nb_conda_kernels\\n'\n",
      "- b'Enabling nb_conda_kernels...\\nStatus: enabled\\n'\n",
      "done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda upgrade --all -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - networkx==2.3.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    networkx-2.3               |             py_0         1.1 MB\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         1.1 MB\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  networkx                                         2.4-py_0 --> 2.3-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "networkx-2.3         | 1.1 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install networkx==2.3.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#needs to show version 2.3\n",
    "\n",
    "import networkx as nx\n",
    "nx.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: failed with initial frozen solve. Retrying with flexible solve.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - snorkel==0.9.0\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
      "    certifi-2019.11.28         |   py36h9f0ad1d_1         149 KB  conda-forge\n",
      "    cudatoolkit-10.0.130       |                0       261.2 MB\n",
      "    cudnn-7.6.5                |       cuda10.0_0       165.0 MB\n",
      "    libprotobuf-3.11.3         |       h8b12597_0         4.8 MB  conda-forge\n",
      "    ninja-1.10.0               |       hc9558a2_0         1.9 MB  conda-forge\n",
      "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
      "    pandas-0.24.2              |   py36hb3f55d8_1        11.1 MB  conda-forge\n",
      "    protobuf-3.11.3            |   py36he1b5a44_0         696 KB  conda-forge\n",
      "    python_abi-3.6             |          1_cp36m           4 KB  conda-forge\n",
      "    pytorch-1.1.0              |cuda100py36he554f03_0       196.2 MB\n",
      "    scikit-learn-0.21.3        |   py36hd81dba3_0         5.0 MB\n",
      "    snorkel-0.9.0              |             py_0          85 KB  conda-forge\n",
      "    tensorboardx-1.9           |             py_0          75 KB  conda-forge\n",
      "    tqdm-4.43.0                |             py_0          47 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:       648.5 MB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  cudatoolkit        pkgs/main/linux-64::cudatoolkit-10.0.130-0\n",
      "  cudnn              pkgs/main/linux-64::cudnn-7.6.5-cuda10.0_0\n",
      "  libprotobuf        conda-forge/linux-64::libprotobuf-3.11.3-h8b12597_0\n",
      "  ninja              conda-forge/linux-64::ninja-1.10.0-hc9558a2_0\n",
      "  protobuf           conda-forge/linux-64::protobuf-3.11.3-py36he1b5a44_0\n",
      "  python_abi         conda-forge/linux-64::python_abi-3.6-1_cp36m\n",
      "  pytorch            pkgs/main/linux-64::pytorch-1.1.0-cuda100py36he554f03_0\n",
      "  snorkel            conda-forge/noarch::snorkel-0.9.0-py_0\n",
      "  tensorboardx       conda-forge/noarch::tensorboardx-1.9-py_0\n",
      "  tqdm               conda-forge/noarch::tqdm-4.43.0-py_0\n",
      "\n",
      "The following packages will be UPDATED:\n",
      "\n",
      "  certifi              pkgs/main::certifi-2019.11.28-py36_0 --> conda-forge::certifi-2019.11.28-py36h9f0ad1d_1\n",
      "\n",
      "The following packages will be SUPERSEDED by a higher-priority channel:\n",
      "\n",
      "  ca-certificates     pkgs/main::ca-certificates-2020.1.1-0 --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
      "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_4 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
      "  pandas             pkgs/main::pandas-1.0.1-py36h0573a6f_0 --> conda-forge::pandas-0.24.2-py36hb3f55d8_1\n",
      "\n",
      "The following packages will be DOWNGRADED:\n",
      "\n",
      "  scikit-learn                        0.22.1-py36hd81dba3_0 --> 0.21.3-py36hd81dba3_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "cudatoolkit-10.0.130 | 261.2 MB  | ##################################### | 100% \n",
      "certifi-2019.11.28   | 149 KB    | ##################################### | 100% \n",
      "tensorboardx-1.9     | 75 KB     | ##################################### | 100% \n",
      "snorkel-0.9.0        | 85 KB     | ##################################### | 100% \n",
      "tqdm-4.43.0          | 47 KB     | ##################################### | 100% \n",
      "protobuf-3.11.3      | 696 KB    | ##################################### | 100% \n",
      "scikit-learn-0.21.3  | 5.0 MB    | ##################################### | 100% \n",
      "libprotobuf-3.11.3   | 4.8 MB    | ##################################### | 100% \n",
      "python_abi-3.6       | 4 KB      | ##################################### | 100% \n",
      "pytorch-1.1.0        | 196.2 MB  | ##################################### | 100% \n",
      "ninja-1.10.0         | 1.9 MB    | ##################################### | 100% \n",
      "ca-certificates-2019 | 145 KB    | ##################################### | 100% \n",
      "pandas-0.24.2        | 11.1 MB   | ##################################### | 100% \n",
      "cudnn-7.6.5          | 165.0 MB  | ##################################### | 100% \n",
      "openssl-1.1.1d       | 2.1 MB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install snorkel==0.9.0 -c conda-forge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: done\n",
      "\n",
      "## Package Plan ##\n",
      "\n",
      "  environment location: /opt/anaconda/envs/Python3\n",
      "\n",
      "  added / updated specs:\n",
      "    - textblob\n",
      "\n",
      "\n",
      "The following packages will be downloaded:\n",
      "\n",
      "    package                    |            build\n",
      "    ---------------------------|-----------------\n",
      "    textblob-0.15.3            |             py_0         595 KB  conda-forge\n",
      "    ------------------------------------------------------------\n",
      "                                           Total:         595 KB\n",
      "\n",
      "The following NEW packages will be INSTALLED:\n",
      "\n",
      "  textblob           conda-forge/noarch::textblob-0.15.3-py_0\n",
      "\n",
      "\n",
      "\n",
      "Downloading and Extracting Packages\n",
      "textblob-0.15.3      | 595 KB    | ##################################### | 100% \n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling import labeling_function\n",
    "from snorkel.labeling import PandasLFApplier,LabelModel\n",
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from itertools import repeat\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from csv import writer\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "import json\n",
    "\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<SparkContext master=local[4] appName=pyspark-shell>\n",
      "<pyspark.sql.session.SparkSession object at 0x7f36562ad898>\n"
     ]
    }
   ],
   "source": [
    "#Spark \n",
    "\n",
    "# Spark Environment\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "import pyspark\n",
    "\n",
    "number_cores = 4\n",
    "memory_gb = 16\n",
    "conf = (\n",
    "    pyspark.SparkConf()\n",
    "        .setMaster('local[{}]'.format(number_cores))\n",
    "        .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    ")\n",
    "sc = pyspark.SparkContext.getOrCreate(conf=conf)\n",
    "print(sc)\n",
    "\n",
    "# get the context\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()\n",
    "print(spark) \n",
    "\n",
    "from pyspark.sql import SQLContext\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape data from the new DVD releases page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = 'https://www.rottentomatoes.com/api/private/v2.0/browse?maxTomato=100&services=amazon%3Bhbo_go%3Bitunes%3Bnetflix_iw%3Bvudu%3Bamazon_prime%3Bfandango_now&certified&sortBy=release&type=dvd-streaming-all&page='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get movie url\n",
    "movie_url = []\n",
    "start_page = 1 ; end_page = 1\n",
    "while start_page <= end_page:\n",
    "#     time.sleep(7)\n",
    "    url = main + str(start_page)\n",
    "    response = requests.get(url)\n",
    "    if response.status_code !=200:\n",
    "        print('Request error')\n",
    "        break\n",
    "    file = json.loads(response.text)\n",
    "    for i in file['results']:\n",
    "        movie_url = movie_url + [i['url']]\n",
    "    start_page +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples for the url:\n",
      "\n",
      "/m/playmobil_the_movie\n",
      "/m/charlies_angels_2019\n",
      "/m/spies_in_disguise\n",
      "\n",
      "Number of movies in list: 32\n"
     ]
    }
   ],
   "source": [
    "print('Examples for the url:\\n')\n",
    "for i in range(3):\n",
    "    print(movie_url[i])\n",
    "print('\\nNumber of movies in list: {}'.format(len(movie_url)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into lists of 50 movies to do the scraping\n",
    "movie_url_split = [movie_url[i:i+50] for i in range(0,600,50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_url_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get reviews from the web\n",
    "reviews = []\n",
    "titles = []\n",
    "ratings = []\n",
    "for split in movie_url_split: # Loop through each split\n",
    "#     time.sleep(7)\n",
    "    for title in split: # Loop through each movie title\n",
    "        url = 'https://www.rottentomatoes.com'+title\n",
    "#         time.sleep(7)\n",
    "        response = requests.get(url)\n",
    "        # Check the request status code\n",
    "        if response.status_code != 200:\n",
    "            print('Request error')\n",
    "            break\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Get labels from each review (fresh vs. rotten)\n",
    "        fresh_rotten = soup.find_all(class_=\"review_quote\")\n",
    "        \n",
    "        # Get movie title\n",
    "        title = soup.find(class_=\"mop-ratings-wrap__title mop-ratings-wrap__title--top\").getText()\n",
    "        \n",
    "        # Get reviews\n",
    "        review = soup.find_all('blockquote')\n",
    "        for i in review:\n",
    "            j = str(i.contents[1])\n",
    "            j = j.replace(\"<p>\\n                    \\n                        \",\"\")\n",
    "            j = j.replace(\"\\n                    \\n                </p>\",\"\")\n",
    "            reviews = reviews + [j]\n",
    "            titles = titles + [title]\n",
    "        \n",
    "        # Identify labels\n",
    "        for i in fresh_rotten:\n",
    "            temp = str(i.findChildren()[2])\n",
    "            if re.search('rotten',temp):\n",
    "                ratings = ratings + ['rotten']\n",
    "            else:\n",
    "                ratings = ratings + ['fresh']\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the DataFrame to store the scraped data\n",
    "df = pd.DataFrame([titles,reviews,ratings],index = ['title','review','rating']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 336 entries, 0 to 336\n",
      "Data columns (total 3 columns):\n",
      "title     336 non-null object\n",
      "review    336 non-null object\n",
      "rating    336 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 10.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Clean the data (drop duplicates, check missing values etc.)\n",
    "df = df.drop_duplicates()\n",
    "df = df.replace([None],np.nan)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Playmobil: The Movie</td>\n",
       "      <td>There is a gentleness and simplicity to the ad...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Playmobil: The Movie</td>\n",
       "      <td>A mess.</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Playmobil: The Movie</td>\n",
       "      <td>This is a vastly inferior toy-to-film IP expan...</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  title                                             review  \\\n",
       "0  Playmobil: The Movie  There is a gentleness and simplicity to the ad...   \n",
       "1  Playmobil: The Movie                                            A mess.   \n",
       "2  Playmobil: The Movie  This is a vastly inferior toy-to-film IP expan...   \n",
       "\n",
       "   rating  \n",
       "0   fresh  \n",
       "1  rotten  \n",
       "2  rotten  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(inplace=True)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to CSV files\n",
    "# df.to_csv('web_scraping_rotten_tomatoes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the scraped data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>Babenco's cinematic farewell isn't perfect by ...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>This is a good film if you are looking for som...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>My Hindu Friend is a celebration of life, love...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>I wouldn't miss it; it's a film that's more th...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>My Hindu Friend (Meu amigo Hindu)</td>\n",
       "      <td>...surreal, reflective (though never sentiment...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                              title  \\\n",
       "0           0  My Hindu Friend (Meu amigo Hindu)   \n",
       "1           1  My Hindu Friend (Meu amigo Hindu)   \n",
       "2           2  My Hindu Friend (Meu amigo Hindu)   \n",
       "3           3  My Hindu Friend (Meu amigo Hindu)   \n",
       "4           4  My Hindu Friend (Meu amigo Hindu)   \n",
       "\n",
       "                                              review rating  \n",
       "0  Babenco's cinematic farewell isn't perfect by ...  fresh  \n",
       "1  This is a good film if you are looking for som...  fresh  \n",
       "2  My Hindu Friend is a celebration of life, love...  fresh  \n",
       "3  I wouldn't miss it; it's a film that's more th...  fresh  \n",
       "4  ...surreal, reflective (though never sentiment...  fresh  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read Web Scraping Data\n",
    "web_scraping_reviews= pd.read_csv('/project/web_scraping_rotten_tomatoes.csv')\n",
    "web_scraping_reviews.head()\n",
    "\n",
    "web_scraping_reviews = web_scraping_reviews.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>4973</td>\n",
       "      <td>Tater Tot &amp; Patton</td>\n",
       "      <td>The title of this film is indicative of the en...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>1171</td>\n",
       "      <td>Liyana</td>\n",
       "      <td>It's that collective experience that carries t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>3548</td>\n",
       "      <td>Brightburn</td>\n",
       "      <td>Exactly the kind of cynical mash-up you'd expe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>1662</td>\n",
       "      <td>Sweetheart</td>\n",
       "      <td>A mysterious, exciting, engrossing movie that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705</th>\n",
       "      <td>4705</td>\n",
       "      <td>Five Feet Apart</td>\n",
       "      <td>If a little too much of the dialogue sounds li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0               title  \\\n",
       "4973        4973  Tater Tot & Patton   \n",
       "1171        1171              Liyana   \n",
       "3548        3548          Brightburn   \n",
       "1662        1662          Sweetheart   \n",
       "4705        4705     Five Feet Apart   \n",
       "\n",
       "                                                 Review Freshness  \n",
       "4973  The title of this film is indicative of the en...         1  \n",
       "1171  It's that collective experience that carries t...         1  \n",
       "3548  Exactly the kind of cynical mash-up you'd expe...         1  \n",
       "1662  A mysterious, exciting, engrossing movie that ...         1  \n",
       "4705  If a little too much of the dialogue sounds li...         1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# rename fresh as 1 and rotten as 0\n",
    "web_scraping_reviews['rating'].replace({'fresh':'1', 'rotten':'0'}, inplace = True)\n",
    "\n",
    "#Rename Rating to Review \n",
    "web_scraping_reviews.rename(columns={'rating':'Freshness', 'review':'Review'},inplace=True)\n",
    "web_scraping_reviews.head()\n",
    "\n",
    "# Extract Review and Freshness columns\n",
    "web_scraping_reviews= pd.DataFrame(web_scraping_reviews, columns = ['Review', 'Freshness'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>The title of this film is indicative of the en...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1171</th>\n",
       "      <td>It's that collective experience that carries t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>Exactly the kind of cynical mash-up you'd expe...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>A mysterious, exciting, engrossing movie that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4705</th>\n",
       "      <td>If a little too much of the dialogue sounds li...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review Freshness\n",
       "4973  The title of this film is indicative of the en...         1\n",
       "1171  It's that collective experience that carries t...         1\n",
       "3548  Exactly the kind of cynical mash-up you'd expe...         1\n",
       "1662  A mysterious, exciting, engrossing movie that ...         1\n",
       "4705  If a little too much of the dialogue sounds li...         1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_scraping_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading & Preparing TSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read TSV file\n",
    "tsv_reviews = pd.read_csv('/project/reviews.tsv', sep='\\t', header=0, encoding='unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>fresh</th>\n",
       "      <th>critic</th>\n",
       "      <th>top_critic</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>A distinctly gallows take on contemporary fina...</td>\n",
       "      <td>3/5</td>\n",
       "      <td>fresh</td>\n",
       "      <td>PJ Nabarro</td>\n",
       "      <td>0</td>\n",
       "      <td>Patrick Nabarro</td>\n",
       "      <td>November 10, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>It's an allegory in search of a meaning that n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>rotten</td>\n",
       "      <td>Annalee Newitz</td>\n",
       "      <td>0</td>\n",
       "      <td>io9.com</td>\n",
       "      <td>May 23, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>... life lived in a bubble in financial dealin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Sean Axmaker</td>\n",
       "      <td>0</td>\n",
       "      <td>Stream on Demand</td>\n",
       "      <td>January 4, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Continuing along a line introduced in last yea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>Daniel Kasman</td>\n",
       "      <td>0</td>\n",
       "      <td>MUBI</td>\n",
       "      <td>November 16, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>... a perverse twist on neorealism...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>fresh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>Cinema Scope</td>\n",
       "      <td>October 12, 2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                             review rating   fresh  \\\n",
       "0   3  A distinctly gallows take on contemporary fina...    3/5   fresh   \n",
       "1   3  It's an allegory in search of a meaning that n...    NaN  rotten   \n",
       "2   3  ... life lived in a bubble in financial dealin...    NaN   fresh   \n",
       "3   3  Continuing along a line introduced in last yea...    NaN   fresh   \n",
       "4   3             ... a perverse twist on neorealism...     NaN   fresh   \n",
       "\n",
       "           critic  top_critic         publisher               date  \n",
       "0      PJ Nabarro           0   Patrick Nabarro  November 10, 2018  \n",
       "1  Annalee Newitz           0           io9.com       May 23, 2018  \n",
       "2    Sean Axmaker           0  Stream on Demand    January 4, 2018  \n",
       "3   Daniel Kasman           0              MUBI  November 16, 2017  \n",
       "4             NaN           0      Cinema Scope   October 12, 2017  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract review and fresh columns\n",
    "tsv_reviews = pd.DataFrame(tsv_reviews, columns = ['review', 'fresh'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>fresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A distinctly gallows take on contemporary fina...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's an allegory in search of a meaning that n...</td>\n",
       "      <td>rotten</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>... life lived in a bubble in financial dealin...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Continuing along a line introduced in last yea...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>... a perverse twist on neorealism...</td>\n",
       "      <td>fresh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review   fresh\n",
       "0  A distinctly gallows take on contemporary fina...   fresh\n",
       "1  It's an allegory in search of a meaning that n...  rotten\n",
       "2  ... life lived in a bubble in financial dealin...   fresh\n",
       "3  Continuing along a line introduced in last yea...   fresh\n",
       "4             ... a perverse twist on neorealism...    fresh"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    5563\n",
       "fresh        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NaN rows in reviews\n",
    "index_name = tsv_reviews[(tsv_reviews['review'].isnull())].index\n",
    "tsv_reviews.drop(index_name, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    0\n",
       "fresh     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tsv_reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename fresh as 1 and rotten as 0\n",
    "tsv_reviews['fresh'].replace({'fresh':'1', 'rotten':'0'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 11857 to 17964\n",
      "Data columns (total 2 columns):\n",
      "Review       5000 non-null object\n",
      "Freshness    5000 non-null object\n",
      "dtypes: object(2)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Rename columns\n",
    "tsv_reviews.rename(columns={'fresh':'Freshness','review':'Review'},inplace=True)\n",
    "tsv_reviews = tsv_reviews.sample(5000)\n",
    "#take 5000\n",
    "tsv_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading & Preparing CSV file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Freshness</th>\n",
       "      <th>Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Manakamana doesn't answer any questions, yet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Wilfully offensive and powered by a chest-thu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>It would be difficult to imagine material mor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Despite the gusto its star brings to the role...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>If there was a good idea at the core of this ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Freshness                                             Review\n",
       "0          1   Manakamana doesn't answer any questions, yet ...\n",
       "1          1   Wilfully offensive and powered by a chest-thu...\n",
       "2          0   It would be difficult to imagine material mor...\n",
       "3          0   Despite the gusto its star brings to the role...\n",
       "4          0   If there was a good idea at the core of this ..."
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read CSV file\n",
    "csv_reviews= pd.read_csv('/project/rotten_tomatoes_reviews.csv')\n",
    "csv_reviews.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249934</th>\n",
       "      <td>While I was able to appreciate what Breillat ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54478</th>\n",
       "      <td>Finbar Lynch is affectingly spiky as the all-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368996</th>\n",
       "      <td>A revolting and shocking work devoid of redem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26689</th>\n",
       "      <td>If you have any interest at all in the subjec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322052</th>\n",
       "      <td>It's a simple tribute to a smart man [Shortz]...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "249934   While I was able to appreciate what Breillat ...          0\n",
       "54478    Finbar Lynch is affectingly spiky as the all-...          1\n",
       "368996   A revolting and shocking work devoid of redem...          0\n",
       "26689    If you have any interest at all in the subjec...          1\n",
       "322052   It's a simple tribute to a smart man [Shortz]...          1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5000 entries, 249934 to 456211\n",
      "Data columns (total 2 columns):\n",
      "Review       5000 non-null object\n",
      "Freshness    5000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 117.2+ KB\n"
     ]
    }
   ],
   "source": [
    "#Swap Freshness and Review \n",
    "columns_titles = [\"Review\",\"Freshness\"]\n",
    "csv_reviews=csv_reviews.reindex(columns=columns_titles)\n",
    "csv_reviews = csv_reviews.sample(5000)\n",
    "\n",
    "csv_reviews.head()\n",
    "csv_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining all the data together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>249934</th>\n",
       "      <td>While I was able to appreciate what Breillat ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54478</th>\n",
       "      <td>Finbar Lynch is affectingly spiky as the all-...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368996</th>\n",
       "      <td>A revolting and shocking work devoid of redem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26689</th>\n",
       "      <td>If you have any interest at all in the subjec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322052</th>\n",
       "      <td>It's a simple tribute to a smart man [Shortz]...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review Freshness\n",
       "249934   While I was able to appreciate what Breillat ...         0\n",
       "54478    Finbar Lynch is affectingly spiky as the all-...         1\n",
       "368996   A revolting and shocking work devoid of redem...         0\n",
       "26689    If you have any interest at all in the subjec...         1\n",
       "322052   It's a simple tribute to a smart man [Shortz]...         1"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concat two files into all_reviews\n",
    "all_reviews=pd.concat([csv_reviews, tsv_reviews,web_scraping_reviews],axis=0, sort=False)\n",
    "all_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 2)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into test and training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews['Freshness'] = all_reviews['Freshness'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(all_reviews,test_size=0.2,stratify = all_reviews['Freshness'],\\\n",
    "                               random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12000 entries, 190043 to 259719\n",
      "Data columns (total 2 columns):\n",
      "Review       12000 non-null object\n",
      "Freshness    12000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 281.2+ KB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3000 entries, 6443 to 439548\n",
      "Data columns (total 2 columns):\n",
      "Review       3000 non-null object\n",
      "Freshness    3000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 70.3+ KB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid off labels in training data \n",
    "train = train.drop('Freshness', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>Aside from [Olga] Kurylenko's steely presence ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>Prey might've been forgivable if it dived head...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276212</th>\n",
       "      <td>It is (perhaps by default) probably the worst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>Cursing, violence in mediocre horror-comedy.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30950</th>\n",
       "      <td>One seemingly terminal problem with the castin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "1118    Aside from [Olga] Kurylenko's steely presence ...          0\n",
       "2213    Prey might've been forgivable if it dived head...          0\n",
       "276212   It is (perhaps by default) probably the worst...          0\n",
       "4435         Cursing, violence in mediocre horror-comedy.          1\n",
       "30950   One seemingly terminal problem with the castin...          0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#From labelled test set\n",
    "#extract a sample to find out about which labelling functions could be written\n",
    "\n",
    "development_split = test.sample(2000,random_state=42)\n",
    "development_split.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>Aside from [Olga] Kurylenko's steely presence ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>Prey might've been forgivable if it dived head...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276212</th>\n",
       "      <td>It is (perhaps by default) probably the worst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>Cursing, violence in mediocre horror-comedy.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30950</th>\n",
       "      <td>One seemingly terminal problem with the castin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "1118    Aside from [Olga] Kurylenko's steely presence ...          0\n",
       "2213    Prey might've been forgivable if it dived head...          0\n",
       "276212   It is (perhaps by default) probably the worst...          0\n",
       "4435         Cursing, violence in mediocre horror-comedy.          1\n",
       "30950   One seemingly terminal problem with the castin...          0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Quick check on development_split df (for finding labeling functions)\n",
    "development_split.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review       2000\n",
       "Freshness    2000\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only necessary to do once \n",
    "# development_split.to_csv('development_split.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into positive and negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4435</th>\n",
       "      <td>Cursing, violence in mediocre horror-comedy.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31007</th>\n",
       "      <td>It might not be the frosted lemon tart that's ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3834</th>\n",
       "      <td>Despite the adherence to a cookie-cutter formu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1809</th>\n",
       "      <td>By dividing us between two conflicting forms -...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4241</th>\n",
       "      <td>The Quiet One isn't a bad documentary on Bill ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Review  Freshness\n",
       "4435        Cursing, violence in mediocre horror-comedy.          1\n",
       "31007  It might not be the frosted lemon tart that's ...          1\n",
       "3834   Despite the adherence to a cookie-cutter formu...          1\n",
       "1809   By dividing us between two conflicting forms -...          1\n",
       "4241   The Quiet One isn't a bad documentary on Bill ...          1"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>Aside from [Olga] Kurylenko's steely presence ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2213</th>\n",
       "      <td>Prey might've been forgivable if it dived head...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276212</th>\n",
       "      <td>It is (perhaps by default) probably the worst...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30950</th>\n",
       "      <td>One seemingly terminal problem with the castin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72289</th>\n",
       "      <td>For prepubescent kids, Bedtime Stories will b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Review  Freshness\n",
       "1118    Aside from [Olga] Kurylenko's steely presence ...          0\n",
       "2213    Prey might've been forgivable if it dived head...          0\n",
       "276212   It is (perhaps by default) probably the worst...          0\n",
       "30950   One seemingly terminal problem with the castin...          0\n",
       "72289    For prepubescent kids, Bedtime Stories will b...          0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "development_split_fresh = development_split[development_split['Freshness'] == 1]\n",
    "development_split_rotten = development_split[development_split['Freshness'] == 0]\n",
    "development_split_fresh.head()\n",
    "development_split_rotten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1174 entries, 4435 to 4535\n",
      "Data columns (total 2 columns):\n",
      "Review       1174 non-null object\n",
      "Freshness    1174 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 27.5+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 826 entries, 1118 to 327262\n",
      "Data columns (total 2 columns):\n",
      "Review       826 non-null object\n",
      "Freshness    826 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 19.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# fresh reviews \n",
    "development_split_fresh.info()\n",
    "# rotten reviews \n",
    "development_split_rotten.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Word occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing punctuation \n",
    "def remove_punctuation(dataframe):\n",
    "    \"\"\"Remove punctuation from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in dataframe.Review.str.lower():\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0            cursing violence in mediocre horrorcomedy\n",
       "1    it might not be the frosted lemon tart thats b...\n",
       "2    despite the adherence to a cookiecutter formul...\n",
       "3    by dividing us between two conflicting forms  ...\n",
       "4    the quiet one isnt a bad documentary on bill w...\n",
       "dtype: object"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from fresh reviews & turn into Series\n",
    "split_fresh= pd.Series(remove_punctuation(development_split_fresh))\n",
    "split_fresh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordList = [\"i\", \"me\", \"my\", \"myself\", \"we\", \"our\", \"ours\", \"ourselves\", \"you\", \"your\", \"yours\", \"yourself\", \"yourselves\",\\\n",
    "                \"he\", \"him\", \"his\", \"himself\", \"she\", \"her\", \"hers\", \"herself\", \"it\", \"its\", \"itself\", \"they\", \"them\", \"their\",\\\n",
    "                \"theirs\", \"themselves\", \"what\", \"which\", \"who\", \"whom\", \"this\", \"that\", \"these\", \"those\", \"am\", \"is\", \"are\", \"was\",\\\n",
    "                \"were\", \"be\", \"been\", \"being\", \"have\", \"has\", \"had\", \"having\", \"do\", \"does\", \"did\", \"doing\", \"a\", \"an\", \"the\", \"and\",\\\n",
    "                \"but\", \"if\", \"or\", \"because\", \"as\", \"until\", \"while\", \"of\", \"at\", \"by\", \"for\", \"with\", \"about\", \"against\", \"between\",\\\n",
    "                \"into\", \"through\", \"during\", \"before\", \"after\", \"above\", \"below\", \"to\", \"from\", \"up\", \"down\", \"in\", \"out\", \"on\", \"off\",\\\n",
    "                \"over\", \"under\", \"again\", \"further\", \"then\", \"once\", \"here\", \"there\", \"when\", \"where\", \"why\", \"how\", \"all\", \"any\",\\\n",
    "                \"both\", \"each\", \"few\", \"more\", \"most\", \"other\", \"some\", \"such\", \"no\", \"nor\", \"not\", \"only\", \"own\", \"same\", \"so\", \"than\",\\\n",
    "                \"very\", \"s\", \"t\", \"can\", \"will\", \"just\", \"don\", \"should\", \"now\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing stopwords from fresh\n",
    "\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_fresh.replace(replacements, regex=True, inplace=True)\n",
    "split_fresh.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization and Count again\n",
    "def stem_recount(df):\n",
    "    import pandas as pd\n",
    "    # Lemmatization\n",
    "    from nltk import LancasterStemmer\n",
    "    st = LancasterStemmer()\n",
    "    newdf = df.copy()\n",
    "    for i in range(0,len(df)):\n",
    "        newdf.iloc[i,0] = st.stem(str(df.iloc[i,0])) \n",
    "        # Plz make sure the word column is the first column in df when using this function\n",
    "    \n",
    "    # Recount\n",
    "    duplicate = newdf[newdf.duplicated(['index'])]\n",
    "    # Plz make sure the 'index' is the column name consisting of words\n",
    "    for i in range(0,len(newdf)):\n",
    "        if i >= len(duplicate):\n",
    "            break\n",
    "        if newdf.iloc[i,0] == duplicate.iloc[i,0]:\n",
    "            newdf.iloc[i,1] = newdf.iloc[i,1] + duplicate.iloc[i,1]\n",
    "    return newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_words_fresh = split_fresh.str.split(expand=True).stack().value_counts()\n",
    "common_words_fresh_df = pd.DataFrame(common_words_fresh)\n",
    "common_words_fresh_df = common_words_fresh_df.rename({0:'Occurence good review'}, axis='columns')\n",
    "new_common_words_fresh_df = common_words_fresh_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>film</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>movy</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>on</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ful</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>review</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>span</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lik</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>good</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ev</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>film</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mak</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>tim</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>much</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>way</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>comedy</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gre</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>dram</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>best</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>us</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>work</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>charact</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>littl</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>too</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>wel</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>nev</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>movy</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>fun</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lov</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>first</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5887</th>\n",
       "      <td>parody</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5888</th>\n",
       "      <td>surv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5889</th>\n",
       "      <td>selfdelud</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5890</th>\n",
       "      <td>gangsta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5891</th>\n",
       "      <td>dirg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5892</th>\n",
       "      <td>acclaim</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5893</th>\n",
       "      <td>bum</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5894</th>\n",
       "      <td>pierc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5895</th>\n",
       "      <td>mendelsohn</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5896</th>\n",
       "      <td>win</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5897</th>\n",
       "      <td>redefin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5898</th>\n",
       "      <td>tribut</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5899</th>\n",
       "      <td>poop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5900</th>\n",
       "      <td>pio</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5901</th>\n",
       "      <td>soso</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>stonefac</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5903</th>\n",
       "      <td>honesty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>swath</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5905</th>\n",
       "      <td>biop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5906</th>\n",
       "      <td>civil</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5907</th>\n",
       "      <td>witty</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5908</th>\n",
       "      <td>bigheart</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5909</th>\n",
       "      <td>selm</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5910</th>\n",
       "      <td>inceiv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5911</th>\n",
       "      <td>tsunam</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5912</th>\n",
       "      <td>nostalg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5913</th>\n",
       "      <td>loy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5914</th>\n",
       "      <td>delicy</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5915</th>\n",
       "      <td>hist</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5916</th>\n",
       "      <td>press</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5917 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           index  Occurence good review\n",
       "0           film                    236\n",
       "1           movy                    147\n",
       "2             on                     83\n",
       "3            ful                     74\n",
       "4          story                     74\n",
       "5         review                     62\n",
       "6           span                     61\n",
       "7            lik                     60\n",
       "8           good                     55\n",
       "9             ev                     49\n",
       "10          film                     45\n",
       "11           mak                     42\n",
       "12           tim                     42\n",
       "13          much                     41\n",
       "14           way                     40\n",
       "15        comedy                     40\n",
       "16           gre                     38\n",
       "17          dram                     38\n",
       "18          best                     38\n",
       "19            us                     48\n",
       "20          work                     37\n",
       "21       charact                     36\n",
       "22         littl                     35\n",
       "23           too                     35\n",
       "24           wel                     35\n",
       "25           nev                     34\n",
       "26          movy                     33\n",
       "27           fun                     33\n",
       "28           lov                     31\n",
       "29         first                     31\n",
       "...          ...                    ...\n",
       "5887      parody                      1\n",
       "5888        surv                      1\n",
       "5889   selfdelud                      1\n",
       "5890     gangsta                      1\n",
       "5891        dirg                      1\n",
       "5892     acclaim                      1\n",
       "5893         bum                      1\n",
       "5894       pierc                      1\n",
       "5895  mendelsohn                      1\n",
       "5896         win                      1\n",
       "5897     redefin                      1\n",
       "5898      tribut                      1\n",
       "5899        poop                      1\n",
       "5900         pio                      1\n",
       "5901        soso                      1\n",
       "5902    stonefac                      1\n",
       "5903     honesty                      1\n",
       "5904       swath                      1\n",
       "5905        biop                      1\n",
       "5906       civil                      1\n",
       "5907       witty                      1\n",
       "5908    bigheart                      1\n",
       "5909        selm                      1\n",
       "5910      inceiv                      1\n",
       "5911      tsunam                      1\n",
       "5912     nostalg                      1\n",
       "5913         loy                      1\n",
       "5914      delicy                      1\n",
       "5915        hist                      1\n",
       "5916       press                      1\n",
       "\n",
       "[5917 rows x 2 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem_recount(new_common_words_fresh_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>full</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>story</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spanish</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>good</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>films</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>make</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comedy</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>great</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>drama</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>best</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>characters</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>little</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>well</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>never</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movies</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fun</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>love</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>references</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>raw</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pieces</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sharp</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rim</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>haunting</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>son</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>en</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ambitious</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sympathetic</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cursing</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>expectations</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>details</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>side</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>three</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tries</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>landscape</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heavy</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>conventions</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vivid</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>slick</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ending</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bleak</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>five</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leave</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>superior</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ago</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>795 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Occurence good review\n",
       "film                            191\n",
       "movie                           114\n",
       "one                              83\n",
       "full                             74\n",
       "story                            74\n",
       "review                           62\n",
       "spanish                          61\n",
       "like                             60\n",
       "good                             55\n",
       "even                             49\n",
       "films                            45\n",
       "make                             42\n",
       "time                             42\n",
       "much                             41\n",
       "way                              40\n",
       "comedy                           40\n",
       "great                            38\n",
       "drama                            38\n",
       "best                             38\n",
       "us                               37\n",
       "work                             37\n",
       "characters                       36\n",
       "little                           35\n",
       "too                              35\n",
       "well                             35\n",
       "never                            34\n",
       "movies                           33\n",
       "fun                              33\n",
       "love                             31\n",
       "first                            31\n",
       "...                             ...\n",
       "references                        4\n",
       "raw                               4\n",
       "pieces                            4\n",
       "sharp                             4\n",
       "rim                               4\n",
       "haunting                          4\n",
       "son                               4\n",
       "en                                4\n",
       "line                              4\n",
       "ambitious                         4\n",
       "sympathetic                       4\n",
       "cursing                           4\n",
       "expectations                      4\n",
       "details                           4\n",
       "side                              4\n",
       "three                             4\n",
       "body                              4\n",
       "level                             4\n",
       "tries                             4\n",
       "landscape                         4\n",
       "heavy                             4\n",
       "conventions                       4\n",
       "vivid                             4\n",
       "slick                             4\n",
       "ending                            4\n",
       "bleak                             4\n",
       "five                              4\n",
       "leave                             4\n",
       "superior                          4\n",
       "ago                               4\n",
       "\n",
       "[795 rows x 1 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get most common words in positive reviews \n",
    "top_common_words_fresh = common_words_fresh_df[common_words_fresh_df['Occurence good review'] >=4]\n",
    "top_common_words_fresh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b> Reason for not using Lemmatization </b>\n",
    "\n",
    "<p>\n",
    "    Before counting the occurance of words in the movie review, we noticed that inflections in words may result in different occurances and thus generating bias during counting. For example, \"enjoy\" and \"enjoyed\" share the same root but would be counted separately if not using Lemmatization.\n",
    "    </p> \n",
    "    \n",
    "<p>\n",
    "    The function \"stem_recount\" takes the root of a word and recounts the occurences. However, it posed a disadvantage of mis-normalizing words into other completely different words. For example, \"movie\" was identified as \"movy\", and \"like\" was identified as \"lik\". We thought this disadvantage exceeds the benefits of correcting word inflection, so we decided to not implement it.\n",
    "    </p> \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    aside from olga kurylenkos steely presence zac...\n",
       "1    prey mightve been forgivable if it dived headf...\n",
       "2     it is perhaps by default probably the worst b...\n",
       "3    one seemingly terminal problem with the castin...\n",
       "4     for prepubescent kids bedtime stories will be...\n",
       "dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Remove punctuation from rotten & turn into Series\n",
    "split_rotten= pd.Series(remove_punctuation(development_split_rotten))\n",
    "split_rotten.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing stopwords from negative reviews\n",
    "replacements = dict(zip((fr'\\b{word}\\b' for word in stopWordList), repeat(\"\")))\n",
    "split_rotten.replace(replacements, regex=True, inplace=True)\n",
    "split_rotten.replace({r' +': ' ', r' +\\.': '.'}, regex=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get most common words in negative reviews \n",
    "\n",
    "common_words_rotten = split_rotten.str.split(expand=True).stack().value_counts()\n",
    "common_words_rotten_df = pd.DataFrame(common_words_rotten)\n",
    "common_words_rotten_df = common_words_rotten_df.rename({0:'Occurence bad review'}, axis='columns')\n",
    "top_common_words_rotten = common_words_rotten_df[common_words_rotten_df['Occurence bad review'] >=4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>film</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movie</th>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Occurence bad review\n",
       "film                    112\n",
       "movie                    92\n",
       "like                     64\n",
       "one                      62\n",
       "much                     49"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_common_words_rotten.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison of good and bad reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "We want to find out which of the words in the good list only appear in the good movies (and not in the bad movies), vice versa and base labeling functions on these findings. We first ened to prepare the data accordingly, before we can write the labelling functions.\n",
    "    <div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_fresh_words_exclusive = top_common_words_fresh.merge(top_common_words_rotten, indicator='i', how='outer', left_index=True,\\\n",
    "                                                         right_index=True).query('i == \"left_only\"').drop('i', 1)\n",
    "\n",
    "top_rotten_words_exclusive = top_common_words_rotten.merge(top_common_words_fresh, indicator='i', how='outer', left_index=True,\\\n",
    "                                                           right_index=True).query('i == \"left_only\"').drop('i', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>across</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>addition</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adults</th>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Occurence good review  Occurence bad review\n",
       "across                      5.0                   NaN\n",
       "addition                    4.0                   NaN\n",
       "adults                      8.0                   NaN\n",
       "age                         6.0                   NaN\n",
       "alone                       4.0                   NaN"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_fresh_words_exclusive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adam</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alien</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>america</th>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>animation</th>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appealing</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Occurence bad review  Occurence good review\n",
       "adam                        4.0                    NaN\n",
       "alien                       5.0                    NaN\n",
       "america                     5.0                    NaN\n",
       "animation                   4.0                    NaN\n",
       "appealing                   6.0                    NaN"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_rotten_words_exclusive.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['across',\n",
       " 'addition',\n",
       " 'adults',\n",
       " 'age',\n",
       " 'alone',\n",
       " 'amazing',\n",
       " 'ambitious',\n",
       " 'among',\n",
       " 'amp',\n",
       " 'appreciated',\n",
       " 'approach',\n",
       " 'arc',\n",
       " 'art',\n",
       " 'artist',\n",
       " 'assured',\n",
       " 'astonishing',\n",
       " 'attitude',\n",
       " 'balance',\n",
       " 'battle',\n",
       " 'beautifully',\n",
       " 'beauty',\n",
       " 'believable',\n",
       " 'beneath',\n",
       " 'biopic',\n",
       " 'black',\n",
       " 'bleak',\n",
       " 'body',\n",
       " 'bond',\n",
       " 'book',\n",
       " 'books',\n",
       " 'brand',\n",
       " 'breezy',\n",
       " 'bright',\n",
       " 'brilliant',\n",
       " 'bringing',\n",
       " 'brings',\n",
       " 'buck',\n",
       " 'call',\n",
       " 'camera',\n",
       " 'campy',\n",
       " 'captivating',\n",
       " 'captures',\n",
       " 'career',\n",
       " 'carter',\n",
       " 'charm',\n",
       " 'charming',\n",
       " 'chilling',\n",
       " 'choice',\n",
       " 'city',\n",
       " 'clear',\n",
       " 'clearly',\n",
       " 'clever',\n",
       " 'cold',\n",
       " 'color',\n",
       " 'combination',\n",
       " 'comedic',\n",
       " 'comedies',\n",
       " 'comingofage',\n",
       " 'completely',\n",
       " 'consistently',\n",
       " 'contemporary',\n",
       " 'continue',\n",
       " 'control',\n",
       " 'conventions',\n",
       " 'core',\n",
       " 'country',\n",
       " 'couple',\n",
       " 'course',\n",
       " 'created',\n",
       " 'crime',\n",
       " 'cry',\n",
       " 'cultural',\n",
       " 'cursing',\n",
       " 'dark',\n",
       " 'darkly',\n",
       " 'darkness',\n",
       " 'days',\n",
       " 'dazzling',\n",
       " 'debut',\n",
       " 'deeper',\n",
       " 'definitely',\n",
       " 'del',\n",
       " 'deliberately',\n",
       " 'delightful',\n",
       " 'delivers',\n",
       " 'despair',\n",
       " 'detail',\n",
       " 'details',\n",
       " 'determined',\n",
       " 'direction',\n",
       " 'disney',\n",
       " 'disturbing',\n",
       " 'documentary',\n",
       " 'dog',\n",
       " 'dramedy',\n",
       " 'drawn',\n",
       " 'early',\n",
       " 'eccentric',\n",
       " 'editing',\n",
       " 'effective',\n",
       " 'effects',\n",
       " 'efforts',\n",
       " 'element',\n",
       " 'emotion',\n",
       " 'en',\n",
       " 'energetic',\n",
       " 'energy',\n",
       " 'engaging',\n",
       " 'enjoyable',\n",
       " 'enjoyed',\n",
       " 'entertain',\n",
       " 'entertainment',\n",
       " 'entire',\n",
       " 'epic',\n",
       " 'exactly',\n",
       " 'excellent',\n",
       " 'exciting',\n",
       " 'executed',\n",
       " 'expectations',\n",
       " 'exploration',\n",
       " 'extremely',\n",
       " 'eye',\n",
       " 'eyes',\n",
       " 'fable',\n",
       " 'facing',\n",
       " 'fact',\n",
       " 'failure',\n",
       " 'fall',\n",
       " 'falls',\n",
       " 'fan',\n",
       " 'fantastic',\n",
       " 'fantasy',\n",
       " 'fascinating',\n",
       " 'fast',\n",
       " 'fastpaced',\n",
       " 'favorite',\n",
       " 'feelgood',\n",
       " 'filmmaking',\n",
       " 'finds',\n",
       " 'fire',\n",
       " 'five',\n",
       " 'focus',\n",
       " 'food',\n",
       " 'foray',\n",
       " 'freedom',\n",
       " 'fresh',\n",
       " 'friends',\n",
       " 'general',\n",
       " 'generation',\n",
       " 'genuinely',\n",
       " 'girl',\n",
       " 'glorious',\n",
       " 'god',\n",
       " 'got',\n",
       " 'grace',\n",
       " 'grand',\n",
       " 'greatest',\n",
       " 'grief',\n",
       " 'gripping',\n",
       " 'gritty',\n",
       " 'grounded',\n",
       " 'happens',\n",
       " 'haunting',\n",
       " 'heartfelt',\n",
       " 'heartwarming',\n",
       " 'high',\n",
       " 'highly',\n",
       " 'hilarious',\n",
       " 'holiday',\n",
       " 'hollywood',\n",
       " 'honest',\n",
       " 'house',\n",
       " 'humanity',\n",
       " 'illness',\n",
       " 'image',\n",
       " 'impact',\n",
       " 'important',\n",
       " 'impressive',\n",
       " 'incredible',\n",
       " 'incredibly',\n",
       " 'individual',\n",
       " 'inherent',\n",
       " 'insightful',\n",
       " 'inspirational',\n",
       " 'inspiring',\n",
       " 'intelligent',\n",
       " 'intensity',\n",
       " 'intimate',\n",
       " 'joe',\n",
       " 'joy',\n",
       " 'jurassic',\n",
       " 'keeps',\n",
       " 'key',\n",
       " 'kid',\n",
       " 'killer',\n",
       " 'known',\n",
       " 'la',\n",
       " 'landscape',\n",
       " 'language',\n",
       " 'laugh',\n",
       " 'lead',\n",
       " 'leads',\n",
       " 'leave',\n",
       " 'leaves',\n",
       " 'lets',\n",
       " 'lies',\n",
       " 'likely',\n",
       " 'limits',\n",
       " 'line',\n",
       " 'lines',\n",
       " 'live',\n",
       " 'living',\n",
       " 'loose',\n",
       " 'loved',\n",
       " 'lovely',\n",
       " 'magic',\n",
       " 'maintains',\n",
       " 'masterful',\n",
       " 'mature',\n",
       " 'mean',\n",
       " 'melancholy',\n",
       " 'men',\n",
       " 'mental',\n",
       " 'mesmerizing',\n",
       " 'message',\n",
       " 'michael',\n",
       " 'middle',\n",
       " 'mix',\n",
       " 'modern',\n",
       " 'moment',\n",
       " 'mood',\n",
       " 'moore',\n",
       " 'morality',\n",
       " 'move',\n",
       " 'moves',\n",
       " 'moving',\n",
       " 'multiple',\n",
       " 'musical',\n",
       " 'must',\n",
       " 'mystery',\n",
       " 'name',\n",
       " 'narration',\n",
       " 'nature',\n",
       " 'necessarily',\n",
       " 'next',\n",
       " 'nice',\n",
       " 'nicely',\n",
       " 'o',\n",
       " 'obvious',\n",
       " 'odd',\n",
       " 'offering',\n",
       " 'others',\n",
       " 'pacing',\n",
       " 'pain',\n",
       " 'park',\n",
       " 'parts',\n",
       " 'party',\n",
       " 'passion',\n",
       " 'past',\n",
       " 'paul',\n",
       " 'personal',\n",
       " 'peter',\n",
       " 'pieces',\n",
       " 'places',\n",
       " 'playful',\n",
       " 'playing',\n",
       " 'pleasure',\n",
       " 'plenty',\n",
       " 'political',\n",
       " 'pop',\n",
       " 'portrait',\n",
       " 'potential',\n",
       " 'powerful',\n",
       " 'presents',\n",
       " 'proves',\n",
       " 'provides',\n",
       " 'provocative',\n",
       " 'psychological',\n",
       " 'que',\n",
       " 'questions',\n",
       " 'quickly',\n",
       " 'quiet',\n",
       " 'quirky',\n",
       " 'race',\n",
       " 'rare',\n",
       " 'raw',\n",
       " 'realism',\n",
       " 'realistic',\n",
       " 'reality',\n",
       " 'recent',\n",
       " 'red',\n",
       " 'redemption',\n",
       " 'references',\n",
       " 'refreshing',\n",
       " 'remarkable',\n",
       " 'resonant',\n",
       " 'result',\n",
       " 'results',\n",
       " 'reveal',\n",
       " 'rich',\n",
       " 'richard',\n",
       " 'ride',\n",
       " 'ridiculous',\n",
       " 'rim',\n",
       " 'rise',\n",
       " 'riveting',\n",
       " 'robert',\n",
       " 'rolling',\n",
       " 'romance',\n",
       " 'romp',\n",
       " 'room',\n",
       " 'sad',\n",
       " 'said',\n",
       " 'satire',\n",
       " 'satirical',\n",
       " 'satisfying',\n",
       " 'school',\n",
       " 'scifi',\n",
       " 'score',\n",
       " 'seeing',\n",
       " 'sending',\n",
       " 'sets',\n",
       " 'setting',\n",
       " 'sexual',\n",
       " 'shame',\n",
       " 'sharp',\n",
       " 'sheer',\n",
       " 'shot',\n",
       " 'showcase',\n",
       " 'showing',\n",
       " 'side',\n",
       " 'sign',\n",
       " 'silly',\n",
       " 'simple',\n",
       " 'skyfall',\n",
       " 'slice',\n",
       " 'slick',\n",
       " 'slight',\n",
       " 'slightly',\n",
       " 'slowly',\n",
       " 'smart',\n",
       " 'social',\n",
       " 'society',\n",
       " 'solid',\n",
       " 'sometimes',\n",
       " 'somewhat',\n",
       " 'son',\n",
       " 'sophisticated',\n",
       " 'sound',\n",
       " 'space',\n",
       " 'special',\n",
       " 'spectacular',\n",
       " 'sports',\n",
       " 'start',\n",
       " 'storytelling',\n",
       " 'strange',\n",
       " 'strength',\n",
       " 'strong',\n",
       " 'study',\n",
       " 'stuff',\n",
       " 'stunning',\n",
       " 'stylish',\n",
       " 'subtle',\n",
       " 'summer',\n",
       " 'superb',\n",
       " 'superior',\n",
       " 'surprise',\n",
       " 'surprising',\n",
       " 'surprisingly',\n",
       " 'suspenseful',\n",
       " 'sweet',\n",
       " 'sympathetic',\n",
       " 'taking',\n",
       " 'talented',\n",
       " 'teen',\n",
       " 'tender',\n",
       " 'terms',\n",
       " 'terrific',\n",
       " 'thanks',\n",
       " 'themes',\n",
       " 'theyre',\n",
       " 'thoughtful',\n",
       " 'thrilling',\n",
       " 'thrills',\n",
       " 'timely',\n",
       " 'title',\n",
       " 'todays',\n",
       " 'told',\n",
       " 'top',\n",
       " 'toros',\n",
       " 'touch',\n",
       " 'touching',\n",
       " 'tough',\n",
       " 'toward',\n",
       " 'toxic',\n",
       " 'traditional',\n",
       " 'tries',\n",
       " 'truth',\n",
       " 'twists',\n",
       " 'understanding',\n",
       " 'unexpected',\n",
       " 'unforgettable',\n",
       " 'unique',\n",
       " 'universe',\n",
       " 'unsettling',\n",
       " 'use',\n",
       " 'utterly',\n",
       " 'vehicle',\n",
       " 'viewed',\n",
       " 'viewer',\n",
       " 'viewers',\n",
       " 'viewing',\n",
       " 'visuals',\n",
       " 'vivid',\n",
       " 'voice',\n",
       " 'wasnt',\n",
       " 'ways',\n",
       " 'western',\n",
       " 'weve',\n",
       " 'whether',\n",
       " 'whimsical',\n",
       " 'whose',\n",
       " 'wild',\n",
       " 'wit',\n",
       " 'within',\n",
       " 'women',\n",
       " 'wonder',\n",
       " 'wonderful',\n",
       " 'wonderfully',\n",
       " 'works',\n",
       " 'writer',\n",
       " 'writerdirector',\n",
       " 'yes',\n",
       " 'youll',\n",
       " 'youve']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only positive words \n",
    "top_fresh_words_exclusive_list = top_fresh_words_exclusive['Occurence good review'].index.tolist()\n",
    "top_fresh_words_exclusive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_fresh_words_exclusive = ['absolutely',\n",
    " 'addition',\n",
    " 'adventure',\n",
    " 'affectionate',\n",
    " 'amazing',\n",
    " 'ambition',\n",
    " 'art',\n",
    " 'artist',\n",
    " 'arts',\n",
    " 'atmosphere',\n",
    " 'attractive',\n",
    " 'awards',\n",
    " 'balance',\n",
    " 'beautiful',\n",
    " 'beautifully',\n",
    " 'beauty',\n",
    " 'bond',\n",
    " 'bright',\n",
    " 'brilliant',\n",
    " 'captivating',\n",
    " 'captures',\n",
    " 'celebration',\n",
    " 'charm',\n",
    " 'charming',\n",
    " 'christmas',\n",
    " 'classic',\n",
    " 'clever',\n",
    " 'committed',\n",
    " 'consistently',\n",
    " 'contemporary',\n",
    " 'conventional',\n",
    " 'convincingly',\n",
    " 'creates',\n",
    " 'creating',\n",
    " 'crowdpleaser',\n",
    " 'cult',\n",
    " 'decade',\n",
    " 'decades',\n",
    " 'deep',\n",
    " 'deeper',\n",
    " 'deeply',\n",
    " 'definitely',\n",
    " 'delightful',\n",
    " 'delightfully',\n",
    " 'depth',\n",
    " 'deserves',\n",
    " 'design',\n",
    " 'details',\n",
    " 'different',\n",
    " 'diverse',\n",
    " 'dramatic',\n",
    " 'early',\n",
    " 'elegant',\n",
    " 'emotionally',\n",
    " 'engaging',\n",
    " 'enjoyable',\n",
    " 'enjoyed',\n",
    " 'equal',\n",
    " 'especially',\n",
    " 'exploration',\n",
    " 'extraordinary',\n",
    " 'extremely',\n",
    " 'familiar',\n",
    " 'famous',\n",
    " 'fan',\n",
    " 'fantastic',\n",
    " 'fantasy',\n",
    " 'fascinating',\n",
    " 'felt',\n",
    " 'filled',\n",
    " 'finest',\n",
    " 'frank',\n",
    " 'fresh',\n",
    " 'friends',\n",
    " 'friendship',\n",
    " 'gags',\n",
    " 'gorgeous',\n",
    " 'grand',\n",
    " 'happy',\n",
    " 'heart',\n",
    " 'hilarious',\n",
    " 'honest',\n",
    " 'hope',\n",
    " 'huge',\n",
    " 'impact',\n",
    " 'insightful',\n",
    " 'inspiring',\n",
    " 'intelligent',\n",
    " 'intense',\n",
    " 'intrigue',\n",
    " 'joy',\n",
    " 'laugh',\n",
    " 'loved',\n",
    " 'mature',\n",
    " 'mind',\n",
    " 'mystery',\n",
    " 'nostalgia',\n",
    " 'novel',\n",
    " 'opening',\n",
    " 'passion',\n",
    " 'perfect',\n",
    " 'performers',\n",
    " 'personal',\n",
    " 'pleasure',\n",
    " 'poignant',\n",
    " 'power',\n",
    " 'powerful',\n",
    " 'precisely',\n",
    " 'profound',\n",
    " 'project',\n",
    " 'proves',\n",
    " 'provide',\n",
    " 'provocative',\n",
    " 'psychological',\n",
    " 'quality',\n",
    " 'remarkable',\n",
    " 'reveals',\n",
    " 'rich',\n",
    " 'riveting',\n",
    " 'satisfying',\n",
    " 'sharp',\n",
    " 'simple',\n",
    " 'smart',\n",
    " 'smile',\n",
    " 'stunning',\n",
    " 'succeeds',\n",
    " 'supernatural',\n",
    " 'surprise',\n",
    " 'surprises',\n",
    " 'surprising',\n",
    " 'surprisingly',\n",
    " 'sweet',\n",
    " 'talents',\n",
    " 'thoughtful',\n",
    " 'thrills',\n",
    " 'touch',\n",
    " 'touching',\n",
    " 'tragedy',\n",
    " 'tragic',\n",
    " 'tribute',\n",
    " 'unique',\n",
    " 'universal',\n",
    " 'warm',\n",
    " 'watchable',\n",
    " 'welcome',\n",
    " 'wit',\n",
    " 'witty',\n",
    " 'wonderful',\n",
    " 'worthwhile',\n",
    " 'worthy']\n",
    "\n",
    "# top_fresh_words_exclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['adam',\n",
       " 'alien',\n",
       " 'america',\n",
       " 'animation',\n",
       " 'appealing',\n",
       " 'attempts',\n",
       " 'awful',\n",
       " 'badly',\n",
       " 'blood',\n",
       " 'box',\n",
       " 'boys',\n",
       " 'break',\n",
       " 'british',\n",
       " 'care',\n",
       " 'central',\n",
       " 'coming',\n",
       " 'concept',\n",
       " 'content',\n",
       " 'couldnt',\n",
       " 'craft',\n",
       " 'credit',\n",
       " 'crisis',\n",
       " 'cute',\n",
       " 'date',\n",
       " 'deliver',\n",
       " 'deserves',\n",
       " 'dialogue',\n",
       " 'didnt',\n",
       " 'difficult',\n",
       " 'disappointing',\n",
       " 'disaster',\n",
       " 'display',\n",
       " 'dull',\n",
       " 'effect',\n",
       " 'effort',\n",
       " 'either',\n",
       " 'episode',\n",
       " 'except',\n",
       " 'execution',\n",
       " 'fails',\n",
       " 'farfetched',\n",
       " 'fashion',\n",
       " 'fat',\n",
       " 'flat',\n",
       " 'flick',\n",
       " 'frustrating',\n",
       " 'given',\n",
       " 'guy',\n",
       " 'hand',\n",
       " 'hasnt',\n",
       " 'heres',\n",
       " 'hero',\n",
       " 'hollow',\n",
       " 'hour',\n",
       " 'iconic',\n",
       " 'id',\n",
       " 'idea',\n",
       " 'incoherent',\n",
       " 'increasingly',\n",
       " 'inside',\n",
       " 'intentions',\n",
       " 'involved',\n",
       " 'ive',\n",
       " 'james',\n",
       " 'joke',\n",
       " 'justify',\n",
       " 'lack',\n",
       " 'lacking',\n",
       " 'lame',\n",
       " 'lazy',\n",
       " 'learn',\n",
       " 'lee',\n",
       " 'lots',\n",
       " 'match',\n",
       " 'means',\n",
       " 'mediocre',\n",
       " 'melodrama',\n",
       " 'merely',\n",
       " 'mess',\n",
       " 'minutes',\n",
       " 'neither',\n",
       " 'netflix',\n",
       " 'nobody',\n",
       " 'opportunity',\n",
       " 'perfectly',\n",
       " 'please',\n",
       " 'pointless',\n",
       " 'possible',\n",
       " 'predictable',\n",
       " 'problem',\n",
       " 'reach',\n",
       " 'redundant',\n",
       " 'relationships',\n",
       " 'remake',\n",
       " 'rest',\n",
       " 'romcom',\n",
       " 'run',\n",
       " 'sadly',\n",
       " 'scares',\n",
       " 'screenplay',\n",
       " 'secret',\n",
       " 'seth',\n",
       " 'shallow',\n",
       " 'shes',\n",
       " 'somewhere',\n",
       " 'soul',\n",
       " 'stars',\n",
       " 'starts',\n",
       " 'stupid',\n",
       " 'supposed',\n",
       " 'suspense',\n",
       " 'talent',\n",
       " 'tedious',\n",
       " 'terrible',\n",
       " 'thin',\n",
       " 'train',\n",
       " 'trick',\n",
       " 'trip',\n",
       " 'try',\n",
       " 'tv',\n",
       " 'twilight',\n",
       " 'twist',\n",
       " 'unfortunately',\n",
       " 'unfunny',\n",
       " 'value',\n",
       " 'version',\n",
       " 'violent',\n",
       " 'wants',\n",
       " 'wedding',\n",
       " 'wish',\n",
       " 'worked',\n",
       " 'worse',\n",
       " 'worst',\n",
       " 'write',\n",
       " 'writers',\n",
       " 'writing',\n",
       " 'written',\n",
       " 'wrong',\n",
       " 'youd']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Get only negative words \n",
    "top_rotten_words_exclusive_list = top_rotten_words_exclusive['Occurence bad review'].index.tolist()\n",
    "top_rotten_words_exclusive_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#take out the ones that seem to make sense: \n",
    "top_rotten_words_exclusive = [\n",
    " 'attempt',\n",
    " 'awkward',\n",
    " 'barely',\n",
    " 'basically',\n",
    " 'bizarre',\n",
    " 'bland',\n",
    " 'boring',\n",
    " 'clumsy',\n",
    " 'comedic',\n",
    " 'disappointing',\n",
    " 'disappointingly',\n",
    " 'disappointment',\n",
    " 'disaster',\n",
    " 'dull',\n",
    " 'effort',\n",
    " 'failed',\n",
    " 'fails',\n",
    " 'generic',\n",
    " 'irritating',\n",
    " 'lacking',\n",
    " 'manic',\n",
    " 'missing',\n",
    " 'nobody',\n",
    " 'noir',\n",
    " 'none',\n",
    " 'painfully',\n",
    " 'pointless',\n",
    " 'poorly',\n",
    " 'problem',\n",
    " 'shallow',\n",
    " 'shame',\n",
    " 'sloppy',\n",
    " 'slow',\n",
    " 'suffers',\n",
    " 'superficial',\n",
    " 'try',\n",
    " 'unfortunately',\n",
    " 'unfunny',\n",
    " 'worst']\n",
    "# top_rotten_words_exclusive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelling Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Word Occurences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  A. Good / bad exclusive words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling.apply.spark import SparkLFApplier\n",
    "\n",
    "from pyspark import SparkContext \n",
    "from pyspark.sql import SQLContext \n",
    "import pandas as pd \n",
    "sqlc=SQLContext(sc) \n",
    "df=pd.read_csv('/project/development_split.csv',index_col = 'Unnamed: 0')\n",
    "df_with_punctuation = df.copy()\n",
    "df['Review'] = remove_punctuation(df)\n",
    "development_split=sqlc.createDataFrame(df)\n",
    "development_split_with_punctuation=sqlc.createDataFrame(df_with_punctuation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+\n",
      "|              Review|Freshness|\n",
      "+--------------------+---------+\n",
      "|vantage point is ...|        0|\n",
      "|the movie makes i...|        0|\n",
      "|claire denis show...|        0|\n",
      "| the plotting is ...|        1|\n",
      "|the movies two ha...|        0|\n",
      "+--------------------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "development_split.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "NOTFRESH = 0\n",
    "FRESH = 1\n",
    "\n",
    "@labeling_function()\n",
    "def fresh(x):\n",
    "    for word in top_fresh_words_exclusive:\n",
    "        word = \" \" +word+\" \"\n",
    "        if word in str(x).lower():\n",
    "            return FRESH\n",
    "    return ABSTAIN\n",
    "#return FRESH if \"best\" in x.str.lower() else ABSTAIN\n",
    "\n",
    "@labeling_function()\n",
    "def rotten(x):\n",
    "    for word in top_rotten_words_exclusive:\n",
    "        word = \" \" +word+\" \"\n",
    "        if word in str(x).lower():\n",
    "            return NOTFRESH\n",
    "    return ABSTAIN\n",
    "#return NOTFRESH if \"best\" in x.str.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [fresh]\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1],\n",
       "       [-1],\n",
       "       [-1],\n",
       "       ...,\n",
       "       [-1],\n",
       "       [ 1],\n",
       "       [-1]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fresh coverage:33.7%\n"
     ]
    }
   ],
   "source": [
    "coverage_fresh = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"fresh coverage:{:.1%}\".format(coverage_fresh[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [rotten]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rotten coverage:7.6%\n"
     ]
    }
   ],
   "source": [
    "coverage_rotten = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"rotten coverage:{:.1%}\".format(coverage_rotten[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Word 'too' occurances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence good review\n",
       "too                     35"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_fresh_df[common_words_fresh_df.index == 'too']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>too</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence bad review\n",
       "too                    49"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_rotten_df[common_words_rotten_df.index == 'too']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def keyword_too(x):\n",
    "    return NOTFRESH if 'too' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [keyword_too]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword too coverage:4.2%\n"
     ]
    }
   ],
   "source": [
    "coverage_keyword_too = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"keyword too coverage:{:.1%}\".format(coverage_keyword_too[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Word 'far' occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence good review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence good review\n",
       "far                     15"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_fresh_df[common_words_fresh_df.index == 'far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Occurence bad review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>far</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Occurence bad review\n",
       "far                    18"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words_rotten_df[common_words_rotten_df.index == 'far']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def keyword_far(x):\n",
    "    return FRESH if 'far' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [keyword_far]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword far coverage:2.7%\n"
     ]
    }
   ],
   "source": [
    "coverage_keyword_far = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"keyword far coverage:{:.1%}\".format(coverage_keyword_far[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. \"n't\" words occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration on the n't\n",
    "# Word occurancy that with punctuation with it\n",
    "\n",
    "# Word occurrences dataframe for fresh reviews\n",
    "development_split_fresh_1 = split_fresh.str.split(expand=True).stack().value_counts()\n",
    "development_split_fresh_df = pd.DataFrame(development_split_fresh_1).reset_index()\n",
    "\n",
    "# Words occurrences dataframe for rotten reviews\n",
    "development_split_rotten_1 = split_rotten.str.split(expand=True).stack().value_counts()\n",
    "development_split_rotten_df = pd.DataFrame(development_split_rotten_1).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "\n",
    "def t(x):\n",
    "    if re.search(\"'t\",str(x).lower()):\n",
    "        return NOTFRESH\n",
    "    return ABSTAIN\n",
    "#return FRESH if \"best\" in x.str.lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [t]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyword far coverage:16.1%\n"
     ]
    }
   ],
   "source": [
    "coverage_t = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"keyword far coverage:{:.1%}\".format(coverage_t[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Occurences of good & bad words from external list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "We also want to look at an imported list of postive and negative words and see whether we can base the labelling functions on them. We take the positive and negative words from (Hu and Liu, 2004), please see reference on the bottom of the page.\n",
    "    </div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing good and bad words & preparing for labelling function \n",
    "#POSITIVE WORDS \n",
    "positive_word = pd.read_csv('/project/positive_words.csv')\n",
    "\n",
    "#sample 500 words \n",
    "positive_word = positive_word.sample(500)\n",
    "\n",
    "#convert it into a list \n",
    "positive_word= positive_word['a+'].tolist()\n",
    "\n",
    "\n",
    "\n",
    "#NEGATIVE WORDS \n",
    "negative_word = pd.read_csv('/project/negative_words.csv')\n",
    "\n",
    "#sample 500 words \n",
    "negative_word = negative_word.sample(500)\n",
    "\n",
    "#convert it into a list \n",
    "negative_word= negative_word['2-faces'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def negative(x): \n",
    "    for word in negative_word:\n",
    "        word = \" \" + word + \" \"\n",
    "        if word in str(x).lower():\n",
    "            return NOTFRESH \n",
    "    return ABSTAIN \n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def positive(x):\n",
    "    for word in positive_word:\n",
    "        word = \" \" + word + \" \"\n",
    "        if word in str(x).lower():\n",
    "            return FRESH \n",
    "    return ABSTAIN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [negative]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative words coverage:8.3%\n"
     ]
    }
   ],
   "source": [
    "coverage_negative = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"negative words coverage:{:.1%}\".format(coverage_negative[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [positive]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive words coverage:29.2%\n"
     ]
    }
   ],
   "source": [
    "coverage_positive = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"positive words coverage:{:.1%}\".format(coverage_positive[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Punctuation occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing for punctuation occurences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn review column into Series\n",
    "development_split_fresh_series = pd.Series(development_split_fresh.Review)\n",
    "development_split_rotten_series = pd.Series(development_split_rotten.Review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive reviews\n",
    "# Split reviews into word\n",
    "fresh_split = pd.Series(development_split_fresh_series.str.split(expand=True).stack())\n",
    "fresh_words = [i for i in fresh_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in fresh_words]\n",
    "fresh_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative reviews\n",
    "# Split reviews into word\n",
    "rotten_split = pd.Series(development_split_rotten_series.str.split(expand=True).stack())\n",
    "rotten_words = [i for i in rotten_split]\n",
    "\n",
    "# Split words into characters\n",
    "def split_str():\n",
    "    return [list(ch) for ch in rotten_words]\n",
    "rotten_split_words = pd.Series(split_str())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn into a flattened list\n",
    "fresh_flattened_list = [y for x in fresh_split_words for y in x]\n",
    "rotten_flattened_list = [y for x in rotten_split_words for y in x]\n",
    "\n",
    "# Count the occurancy of each character\n",
    "# Positive reviews\n",
    "fresh_split_characters = pd.Series(fresh_flattened_list).value_counts()\n",
    "fresh_split_characters = pd.DataFrame(fresh_split_characters).reset_index()\n",
    "\n",
    "# Negative reviews\n",
    "rotten_split_characters = pd.Series(rotten_flattened_list).value_counts()\n",
    "rotten_split_characters = pd.DataFrame(rotten_split_characters).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Question mark occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>?</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "62     ?  21"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>?</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "55     ?  30"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '?' in rotten reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '?']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Can you inflate a gimmick-driven comedy skit into a full-fledged feature film? Up to a point.', 'Amusing, perhaps, but really funny? No.', 'Does the excellence of the second part make up for the rancid, unintentionally campy opening? Not for me, though perhaps others would be more forgiving.']\n"
     ]
    }
   ],
   "source": [
    "list_with_question_mark = []\n",
    "for review in development_split_rotten.Review:\n",
    "    if '?' in review:\n",
    "        list_with_question_mark.append(review)\n",
    "        \n",
    "print (list_with_question_mark[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def question_mark(x):\n",
    "    return NOTFRESH if '?' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lfs = [question_mark]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split_with_punctuation.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question mark coverage:2.1%\n"
     ]
    }
   ],
   "source": [
    "coverage_question_mark = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"question mark coverage:{:.1%}\".format(coverage_question_mark[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Exclamation mark occurrences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>!</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index   0\n",
       "61     !  22"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '!' in fresh reviews\n",
    "fresh_split_characters[fresh_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>!</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  0\n",
       "68     !  6"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the # of occurance of '!' in rotten reviews\n",
    "rotten_split_characters[rotten_split_characters['index'] == '!']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def exclamation_mark(x):\n",
    "    return FRESH if '!' in str(x).lower() else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lfs = [exclamation_mark]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "sample_L = applier.apply(development_split_with_punctuation.rdd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exclamation mark coverage:0.7%\n"
     ]
    }
   ],
   "source": [
    "coverage_exclamation_mark = (sample_L != ABSTAIN).mean(axis=0)\n",
    "print(\"exclamation mark coverage:{:.1%}\".format(coverage_exclamation_mark[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.preprocess import preprocessor\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSentiment(text):\n",
    "    x = {}\n",
    "    x[\"polarity\"] = TextBlob(text).sentiment.polarity\n",
    "    x[\"subjectivity\"] = TextBlob(text).sentiment.subjectivity\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "@labeling_function()\n",
    "def textblob_polarity(x):\n",
    "    x = getSentiment(x.Review)\n",
    "    return FRESH if x[\"polarity\"] > 0.8 else ABSTAIN\n",
    "\n",
    "\n",
    "@labeling_function()\n",
    "def textblob_subjectivity(x):\n",
    "    x = getSentiment(x.Review)\n",
    "    return FRESH if x[\"subjectivity\"] >= 0.5 else ABSTAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [\n",
    "       textblob_polarity,\n",
    "       textblob_subjectivity\n",
    "      ]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "\n",
    "sample_L = applier.apply(development_split.rdd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>textblob_polarity</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <td>1</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       j Polarity  Coverage  Overlaps  Conflicts\n",
       "textblob_polarity      0      [1]    0.0120    0.0075        0.0\n",
       "textblob_subjectivity  1      [1]    0.5635    0.0075        0.0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(sample_L, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Combining labelling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Next, we want to combine all the labelling functions into one and apply them to the training set. However, as the labelling functions around the punctuation have very low coverages, we decided not to include these.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfs = [fresh,\n",
    "       rotten,\n",
    "       keyword_too,\n",
    "       keyword_far,\n",
    "       t,\n",
    "       negative,\n",
    "       positive,\n",
    "       textblob_polarity,\n",
    "       textblob_subjectivity\n",
    "      ]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "\n",
    "sample_L = applier.apply(development_split.rdd)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fresh</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.3365</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>0.1035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotten</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0630</td>\n",
       "      <td>0.0595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_too</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_far</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.0080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.1605</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>0.1200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>5</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.0740</td>\n",
       "      <td>0.0705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.2925</td>\n",
       "      <td>0.2465</td>\n",
       "      <td>0.0870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_polarity</th>\n",
       "      <td>7</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_subjectivity</th>\n",
       "      <td>8</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.5635</td>\n",
       "      <td>0.4050</td>\n",
       "      <td>0.1845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       j Polarity  Coverage  Overlaps  Conflicts\n",
       "fresh                  0      [1]    0.3365    0.2775     0.1035\n",
       "rotten                 1      [0]    0.0765    0.0630     0.0595\n",
       "keyword_too            2      [0]    0.0425    0.0325     0.0300\n",
       "keyword_far            3      [1]    0.0270    0.0245     0.0080\n",
       "t                      4      [0]    0.1605    0.1255     0.1200\n",
       "negative               5      [0]    0.0830    0.0740     0.0705\n",
       "positive               6      [1]    0.2925    0.2465     0.0870\n",
       "textblob_polarity      7      [1]    0.0120    0.0120     0.0025\n",
       "textblob_subjectivity  8      [1]    0.5635    0.4050     0.1845"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(sample_L, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "As seen above, with our labelling functions we obtain high conflicts for the \"t\" labelling function, as well as for the \"textblob_subjectivity\" therefore we decided to remove these two lfs from our model. \n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New lfs without t & textblob subjectivity \n",
    "lfs = [fresh,\n",
    "       rotten,\n",
    "       keyword_too,\n",
    "       keyword_far,\n",
    "       negative,\n",
    "       positive,\n",
    "       textblob_polarity\n",
    "      ]\n",
    "\n",
    "applier = SparkLFApplier(lfs)\n",
    "\n",
    "sample_L = applier.apply(development_split.rdd)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>j</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Coverage</th>\n",
       "      <th>Overlaps</th>\n",
       "      <th>Conflicts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>fresh</th>\n",
       "      <td>0</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.3365</td>\n",
       "      <td>0.1755</td>\n",
       "      <td>0.0610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rotten</th>\n",
       "      <td>1</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0460</td>\n",
       "      <td>0.0365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_too</th>\n",
       "      <td>2</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword_far</th>\n",
       "      <td>3</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0270</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.0045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>negative</th>\n",
       "      <td>4</td>\n",
       "      <td>[0]</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.0420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>5</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.2925</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.0470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>textblob_polarity</th>\n",
       "      <td>6</td>\n",
       "      <td>[1]</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   j Polarity  Coverage  Overlaps  Conflicts\n",
       "fresh              0      [1]    0.3365    0.1755     0.0610\n",
       "rotten             1      [0]    0.0765    0.0460     0.0365\n",
       "keyword_too        2      [0]    0.0425    0.0240     0.0200\n",
       "keyword_far        3      [1]    0.0270    0.0175     0.0045\n",
       "negative           4      [0]    0.0830    0.0515     0.0420\n",
       "positive           5      [1]    0.2925    0.1625     0.0470\n",
       "textblob_polarity  6      [1]    0.0120    0.0085     0.0010"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LFAnalysis(sample_L, lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing punctuation from training set \n",
    "train_prepared = train.copy()\n",
    "train_prepared['Review'] = remove_punctuation(train_prepared)\n",
    "\n",
    "#Removing punctuation from test set \n",
    "test_prepared = test.copy()\n",
    "test_prepared['Review'] = remove_punctuation(test_prepared)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting in training and testing & applying lfs\n",
    "\n",
    "L_train=sqlc.createDataFrame(train_prepared)\n",
    "\n",
    "L_test = sqlc.createDataFrame(test_prepared)\n",
    "\n",
    "\n",
    "L_train = applier.apply(L_train.rdd)\n",
    "\n",
    "L_test = applier.apply(L_test.rdd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. MajorityLabelVoter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Now that we have the combined labels, we will convert the result from these labels to predict the class for our training data. The first approach is to take the majority vote from all of the labels. If more labels predicted that the review is fresh, then it will be labelled as 1 and vice versa.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.labeling import MajorityLabelVoter\n",
    "\n",
    "majority_model = MajorityLabelVoter()\n",
    "preds_train = majority_model.predict(L=L_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000,)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.3'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#needs to show version 2.3\n",
    "import networkx as nx\n",
    "nx.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. LabelModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "Another approach to predict the labels is the Snorkel LabelModel. This is a more refined approach compared to the majority vote because it assigns different weights to each of the labelling function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Labelling according to weights \n",
    "from snorkel.labeling import LabelModel\n",
    "\n",
    "label_model = LabelModel(cardinality=2, verbose=True)\n",
    "label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = test['Freshness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Majority Vote Accuracy:   61.3%\n",
      "Label Model Accuracy:     60.4%\n"
     ]
    }
   ],
   "source": [
    "majority_acc = majority_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%\")\n",
    "\n",
    "label_model_acc = label_model.score(L=L_test, Y=Y_test, tie_break_policy=\"random\")[\n",
    "    \"accuracy\"\n",
    "]\n",
    "print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "By comparing the accuracy from both methods, it could be seen that the Label Model has slightly lower accuracy compared to the Majority Vote.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will compare the difference between classifier A which is built with small dataset (2000 labelled data points) and classifier B built from additional weak labelled data (2000 labelled + 12.000 weak labeled data points). We will test it on a separate test data (1000 labelled data points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/faculty/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/faculty/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/faculty/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langid\n",
      "  Downloading langid-1.1.6.tar.gz (1.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9 MB 43.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/anaconda/envs/Python3/lib/python3.6/site-packages (from langid) (1.18.1)\n",
      "Building wheels for collected packages: langid\n",
      "  Building wheel for langid (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langid: filename=langid-1.1.6-py3-none-any.whl size=1941188 sha256=f053f7b0c646f4a4759e3d2790df257fd9ffa94a540c13cb5b4ecd7a2ee155ad\n",
      "  Stored in directory: /home/faculty/.cache/pip/wheels/b4/77/b4/b38806c8087e0860cfeabab1f96b60c48346d8db59a9254787\n",
      "Successfully built langid\n",
      "Installing collected packages: langid\n",
      "Successfully installed langid-1.1.6\n"
     ]
    }
   ],
   "source": [
    "# Download libraries\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "!pip install langid\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType\n",
    "import preproc as pp\n",
    "\n",
    "# Preproc.py is a 3rd party function by dreyco676 to help with text preprocessing\n",
    "# Register all the functions in preproc.py with Spark Context\n",
    "check_lang_udf = udf(pp.check_lang, StringType())\n",
    "remove_stops_udf = udf(pp.remove_stops, StringType())\n",
    "remove_features_udf = udf(pp.remove_features, StringType())\n",
    "tag_and_remove_udf = udf(pp.tag_and_remove, StringType())\n",
    "lemmatize_udf = udf(pp.lemmatize, StringType())\n",
    "check_blanks_udf = udf(pp.check_blanks, StringType())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|vantage point is ...|    0|\n",
      "|the movie makes i...|    0|\n",
      "|claire denis show...|    0|\n",
      "| the plotting is ...|    1|\n",
      "|the movies two ha...|    0|\n",
      "|the first feature...|    1|\n",
      "|misses the sense ...|    0|\n",
      "|the movie is a fa...|    1|\n",
      "| in the end prett...|    0|\n",
      "|follows some of t...|    1|\n",
      "|even in its most ...|    1|\n",
      "|when the story sh...|    1|\n",
      "|a thrilling but f...|    1|\n",
      "|it remains watcha...|    1|\n",
      "|softness of bodie...|    0|\n",
      "| cusack who selfd...|    1|\n",
      "| knightleys sugar...|    0|\n",
      "| best of all is p...|    1|\n",
      "|none of the filmm...|    0|\n",
      "|filled with clich...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Read the data\n",
    "review_df = development_split\n",
    "\n",
    "# Rename Column\n",
    "review_df = review_df.withColumnRenamed('Review','text')\n",
    "review_df = review_df.withColumnRenamed('Freshness','label')\n",
    "review_df = review_df.withColumnRenamed('_c0','index')\n",
    "\n",
    "# Remove Null\n",
    "review_df = review_df.filter(review_df.label. isNotNull())\n",
    "\n",
    "# Change data type to Integer\n",
    "review_df = review_df.withColumn(\"label\", review_df[\"label\"].cast(IntegerType()))\n",
    "\n",
    "# Show df information\n",
    "review_df.show()\n",
    "review_df.printSchema()\n",
    "review_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|vantage point thr...|    0|\n",
      "|movie make point ...|    0|\n",
      "|claire denis show...|    0|\n",
      "|plot predictable ...|    1|\n",
      "|movie halve larde...|    0|\n",
      "|first feature cre...|    1|\n",
      "|miss sense menace...|    0|\n",
      "|movie convince fa...|    1|\n",
      "|end pink fraudule...|    0|\n",
      "|follow drug thril...|    1|\n",
      "|inspired moment s...|    1|\n",
      "|story shift nashv...|    1|\n",
      "|thrill frivolous ...|    1|\n",
      "|remains watchable...|    1|\n",
      "|softness body wor...|    0|\n",
      "|cusack mock iconi...|    1|\n",
      "|knightleys sugar ...|    0|\n",
      "|best parker perfe...|    1|\n",
      "|none filmmaking a...|    0|\n",
      "|fill cliche runof...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "\n",
    "# remove stop words to reduce dimensionality\n",
    "review_df = review_df.withColumn(\"text\", remove_stops_udf(review_df[\"text\"]))\n",
    "\n",
    "# remove other non essential words\n",
    "review_df = review_df.withColumn(\"text\", remove_features_udf(review_df[\"text\"]))\n",
    "\n",
    "# tag the words remaining and keep only Nouns, Verbs and Adjectives\n",
    "review_df = review_df.withColumn(\"text\", tag_and_remove_udf(review_df[\"text\"]))\n",
    "\n",
    "# lemmatization of remaining words to reduce dimensionality & boost measures\n",
    "review_df = review_df.withColumn(\"text\", lemmatize_udf(review_df[\"text\"]))\n",
    "\n",
    "review_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|Freshness|\n",
      "+---------+\n",
      "|        0|\n",
      "|        1|\n",
      "+---------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[index: string, Unnamed: 0: string, text: string, label: string]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+--------------------+-----+\n",
      "|index|Unnamed: 0|                text|label|\n",
      "+-----+----------+--------------------+-----+\n",
      "|    0|         1|A cornball drone ...|    0|\n",
      "|    1|         3|I don't like impo...|    0|\n",
      "|    2|         4| The Void marks a...|    1|\n",
      "|    3|         5|The only way to l...|    0|\n",
      "|    4|         9| a tame and insul...|    0|\n",
      "|    5|        10|How sorry can you...|    0|\n",
      "|    6|        11|\"Though not parti...|    1|\n",
      "|    7|        16|\"\"\"Blood\"\" [chapt...|    1|\n",
      "|    8|        19|The lack of empat...|    0|\n",
      "|    9|        21|This modern fanta...|    1|\n",
      "|   10|        22|The best film I'v...|    0|\n",
      "|   11|        27| After being surp...|    0|\n",
      "|   12|        34|  An inert thriller.|    0|\n",
      "|   13|        35|What cannot be ar...|    1|\n",
      "|   14|        36|Amid the glut of ...|    1|\n",
      "|   15|        38|It is ultimately ...|    0|\n",
      "|   16|        40|I laughed frequen...|    0|\n",
      "|   17|        42|Fighting with My ...|    1|\n",
      "|   18|        46|Weinstein walks a...|    1|\n",
      "|   19|        47|[A] frenetic jumb...|    0|\n",
      "+-----+----------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- index: string (nullable = true)\n",
      " |-- Unnamed: 0: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- label: integer (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Specify Training and Test data\n",
    "training_df = review_df\n",
    "test_df = sqlContext.read.csv('/project/1000_labels_v2.csv', header=True,sep = '~')\n",
    "test_df.select('Freshness').distinct().show()\n",
    "\n",
    "# Rename Column\n",
    "test_df = test_df.withColumnRenamed('Review','text')\n",
    "test_df = test_df.withColumnRenamed('Freshness','label')\n",
    "test_df = test_df.withColumnRenamed('_c0','index')\n",
    "\n",
    "# Remove Null\n",
    "test_df.filter(test_df.label.isNotNull())\n",
    "\n",
    "# Change data type to Integer\n",
    "test_df = test_df.withColumn(\"label\", test_df[\"label\"].cast(IntegerType()))\n",
    "\n",
    "test_df.show()\n",
    "test_df.printSchema()\n",
    "test_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+----------+\n",
      "|                text|label|prediction|\n",
      "+--------------------+-----+----------+\n",
      "|A cornball drone ...|    0|       0.0|\n",
      "|I don't like impo...|    0|       1.0|\n",
      "| The Void marks a...|    1|       0.0|\n",
      "|The only way to l...|    0|       1.0|\n",
      "| a tame and insul...|    0|       1.0|\n",
      "|How sorry can you...|    0|       0.0|\n",
      "|\"Though not parti...|    1|       1.0|\n",
      "|\"\"\"Blood\"\" [chapt...|    1|       1.0|\n",
      "|The lack of empat...|    0|       1.0|\n",
      "|This modern fanta...|    1|       1.0|\n",
      "|The best film I'v...|    0|       1.0|\n",
      "| After being surp...|    0|       1.0|\n",
      "|  An inert thriller.|    0|       0.0|\n",
      "|What cannot be ar...|    1|       1.0|\n",
      "|Amid the glut of ...|    1|       0.0|\n",
      "|It is ultimately ...|    0|       0.0|\n",
      "|I laughed frequen...|    0|       1.0|\n",
      "|Fighting with My ...|    1|       1.0|\n",
      "|Weinstein walks a...|    1|       1.0|\n",
      "|[A] frenetic jumb...|    0|       0.0|\n",
      "+--------------------+-----+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import MLib\n",
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import ParamGridBuilder\n",
    "from pyspark.ml.tuning import CrossValidator\n",
    "\n",
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and nb.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol='words', outputCol=\"features\")\n",
    "idf = IDF(minDocFreq=3, inputCol=\"features\", outputCol=\"idf\")\n",
    "nb = NaiveBayes()\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, nb])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 1.0]).build()\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)\n",
    "\n",
    "# Fit the model to the 1st training dataset (2000 labeled data points)\n",
    "cvModel = cv.fit(training_df)\n",
    "\n",
    "result = cvModel.transform(test_df)\n",
    "prediction_df = result.select(\"text\", \"label\", \"prediction\")\n",
    "prediction_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6236236236236237"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Evaluate the Accuracy\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(result, {evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifier B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|vantage point thr...|    0|\n",
      "|movie make point ...|    0|\n",
      "|claire denis show...|    0|\n",
      "|plot predictable ...|    1|\n",
      "|movie halve larde...|    0|\n",
      "|first feature cre...|    1|\n",
      "|miss sense menace...|    0|\n",
      "|movie convince fa...|    1|\n",
      "|end pink fraudule...|    0|\n",
      "|follow drug thril...|    1|\n",
      "|inspired moment s...|    1|\n",
      "|story shift nashv...|    1|\n",
      "|thrill frivolous ...|    1|\n",
      "|remains watchable...|    1|\n",
      "|softness body wor...|    0|\n",
      "|cusack mock iconi...|    1|\n",
      "|knightleys sugar ...|    0|\n",
      "|best parker perfe...|    1|\n",
      "|none filmmaking a...|    0|\n",
      "|fill cliche runof...|    0|\n",
      "+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "13997"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data for 2000 labelled data points and 12.000 weakly labelled data points\n",
    "review_df_2000 = review_df\n",
    "review_df_12000 = sqlContext.read.csv('/project/12000_predicted_labels_v2.csv', header=True,sep='~')\n",
    "\n",
    "# Remove Null\n",
    "review_df_12000 = review_df_12000.filter(review_df_12000.predicted_train.isNotNull())\n",
    "\n",
    "#Change Column name and type\n",
    "review_df_12000 = review_df_12000.withColumnRenamed('Review','text')\n",
    "review_df_12000 = review_df_12000.withColumnRenamed('predicted_train','label')\n",
    "review_df_12000 = review_df_12000.withColumn(\"label\", review_df_12000[\"label\"].cast(IntegerType()))\n",
    "review_df_12000 = review_df_12000.filter(review_df_12000.label.isNotNull())\n",
    "\n",
    "# remove stop words to reduce dimensionality\n",
    "review_df_12000 = review_df_12000.withColumn(\"text\", remove_stops_udf(review_df_12000[\"text\"]))\n",
    "\n",
    "# remove other non essential words\n",
    "review_df_12000 = review_df_12000.withColumn(\"text\", remove_features_udf(review_df_12000[\"text\"]))\n",
    "\n",
    "# tag the words remaining and keep only Nouns, Verbs and Adjectives\n",
    "review_df_12000 = review_df_12000.withColumn(\"text\", tag_and_remove_udf(review_df_12000[\"text\"]))\n",
    "\n",
    "# lemmatization of remaining words to reduce dimensionality & boost measures\n",
    "review_df_12000 = review_df_12000.withColumn(\"text\", lemmatize_udf(review_df_12000[\"text\"]))\n",
    "\n",
    "# Create Training_df_2 by combining 2000 labeled data points and12000 weak labeled data points\n",
    "training_df_2 = review_df_2000.union(review_df_12000.select(['text','label']))\n",
    "\n",
    "training_df_2.show()\n",
    "training_df_2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5815815815815816"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure an ML pipeline, which consists of tree stages: tokenizer, hashingTF, and nb.\n",
    "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
    "hashingTF = HashingTF(inputCol='words', outputCol=\"features\")\n",
    "idf = IDF(minDocFreq=3, inputCol=\"features\", outputCol=\"idf\")\n",
    "nb = NaiveBayes()\n",
    "pipeline = Pipeline(stages=[tokenizer, hashingTF, idf, nb])\n",
    "\n",
    "\n",
    "paramGrid = ParamGridBuilder().addGrid(nb.smoothing, [0.0, 1.0]).build()\n",
    "\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline, \n",
    "                    estimatorParamMaps=paramGrid, \n",
    "                    evaluator=MulticlassClassificationEvaluator(), \n",
    "                    numFolds=4)\n",
    "\n",
    "# Fit the model to the new training set (14.000 data points)\n",
    "cvModel = cv.fit(training_df_2)\n",
    "\n",
    "result = cvModel.transform(test_df)\n",
    "prediction_df = result.select(\"text\", \"label\", \"prediction\")\n",
    "\n",
    "#Evaluate the accuracy of 2nd model\n",
    "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\")\n",
    "evaluator.evaluate(result, {evaluator.metricName: \"accuracy\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier we produced with 3.000 data points performed with 62% accuracy. Meanwhile, the classifier we created from an extra 10.000 weak labeled data points performed with 58% accuracy. The drop in accuracy might be due to the low accuracy of our labelling function, being only around 60%. Rather than improving the accuracy, it instead cause some noises to our dataset which in turn reduced the performance of our model. To get a better results, we might need to introduce new labelling functions or improve current ones. Aside from that, we could also try different models with increased complexity such as neural network with pre-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Minqing Hu and Bing Liu. \"Mining and Summarizing Customer Reviews.\" \n",
    ";       Proceedings of the ACM SIGKDD International Conference on Knowledge \n",
    ";       Discovery and Data Mining (KDD-2004), Aug 22-25, 2004, Seattle, \n",
    ";       Washington, USA, \n",
    "\n",
    "GitHub. 2020. Dreyco676/Nlp_Spark. [online] Available at: <https://github.com/dreyco676/nlp_spark/blob/master/nlp_with_spark.ipynb> [Accessed 12 March 2020]."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python3]",
   "language": "python",
   "name": "conda-env-Python3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
